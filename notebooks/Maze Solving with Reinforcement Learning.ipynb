{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Dig In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map\n",
    "We start with a 7x7 map that contains barriers and enemies that, if touched, will do damage to the user. If the user tries to go off out of the 7x7 map, then they will take damage as well.\n",
    "\n",
    "### Rules\n",
    "The purpose of this game is to manuever around the barriers and enemies to get the treasure. The treasure is always located in the bottom rightmost square. We start the user in a randomly determined location on the map. \n",
    "\n",
    "*(This is so a machine learning model cannot figure out a path to do every time)*\n",
    "\n",
    "### Machine Learning\n",
    "For this we are using a reinforcement deep learning. Let's see how things go. We are going to have our model start playing games where it decides what direction to go without us telling it where to go or what the objective is. We are then going to give feedback based on those moves. If it tries to leave the map, we let it know that it took damage and lost. If it finds the treasure, we are going to tell it that it won. This feedback will be feed to our model many many times. The only way our model learns is by this feedback. Once our model has 100% win-rate, we will end the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import maze_solver as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/14999 | Loss: 0.0303 | Episodes: 105 | Win count: 0 | Win rate: 0.000 | time: 4.3 seconds\n",
      "Epoch: 001/14999 | Loss: 0.0037 | Episodes: 107 | Win count: 0 | Win rate: 0.000 | time: 8.6 seconds\n",
      "Epoch: 002/14999 | Loss: 0.0026 | Episodes: 102 | Win count: 0 | Win rate: 0.000 | time: 12.9 seconds\n",
      "Epoch: 003/14999 | Loss: 0.0010 | Episodes: 101 | Win count: 0 | Win rate: 0.000 | time: 17.0 seconds\n",
      "Epoch: 004/14999 | Loss: 0.0026 | Episodes: 104 | Win count: 0 | Win rate: 0.000 | time: 21.2 seconds\n",
      "Epoch: 005/14999 | Loss: 0.0041 | Episodes: 28 | Win count: 1 | Win rate: 0.000 | time: 22.4 seconds\n",
      "Epoch: 006/14999 | Loss: 0.0017 | Episodes: 105 | Win count: 1 | Win rate: 0.000 | time: 26.6 seconds\n",
      "Epoch: 007/14999 | Loss: 0.0042 | Episodes: 11 | Win count: 2 | Win rate: 0.000 | time: 27.1 seconds\n",
      "Epoch: 008/14999 | Loss: 0.0239 | Episodes: 1 | Win count: 3 | Win rate: 0.000 | time: 27.1 seconds\n",
      "Epoch: 009/14999 | Loss: 0.0387 | Episodes: 18 | Win count: 4 | Win rate: 0.000 | time: 28.0 seconds\n",
      "Epoch: 010/14999 | Loss: 0.0026 | Episodes: 104 | Win count: 4 | Win rate: 0.000 | time: 32.2 seconds\n",
      "Epoch: 011/14999 | Loss: 0.0025 | Episodes: 107 | Win count: 4 | Win rate: 0.000 | time: 36.5 seconds\n",
      "Epoch: 012/14999 | Loss: 0.0034 | Episodes: 107 | Win count: 4 | Win rate: 0.000 | time: 40.9 seconds\n",
      "Epoch: 013/14999 | Loss: 0.0014 | Episodes: 77 | Win count: 5 | Win rate: 0.000 | time: 44.0 seconds\n",
      "Epoch: 014/14999 | Loss: 0.0255 | Episodes: 8 | Win count: 6 | Win rate: 0.000 | time: 44.3 seconds\n",
      "Epoch: 015/14999 | Loss: 0.0021 | Episodes: 107 | Win count: 6 | Win rate: 0.000 | time: 48.5 seconds\n",
      "Epoch: 016/14999 | Loss: 0.0063 | Episodes: 106 | Win count: 6 | Win rate: 0.000 | time: 52.7 seconds\n",
      "Epoch: 017/14999 | Loss: 0.0020 | Episodes: 101 | Win count: 6 | Win rate: 0.000 | time: 56.8 seconds\n",
      "Epoch: 018/14999 | Loss: 0.0027 | Episodes: 3 | Win count: 7 | Win rate: 0.000 | time: 56.9 seconds\n",
      "Epoch: 019/14999 | Loss: 0.0170 | Episodes: 4 | Win count: 8 | Win rate: 0.000 | time: 57.1 seconds\n",
      "Epoch: 020/14999 | Loss: 0.0019 | Episodes: 104 | Win count: 8 | Win rate: 0.000 | time: 61.2 seconds\n",
      "Epoch: 021/14999 | Loss: 0.0309 | Episodes: 39 | Win count: 9 | Win rate: 0.000 | time: 62.7 seconds\n",
      "Epoch: 022/14999 | Loss: 0.0334 | Episodes: 4 | Win count: 10 | Win rate: 0.000 | time: 62.9 seconds\n",
      "Epoch: 023/14999 | Loss: 0.0020 | Episodes: 4 | Win count: 11 | Win rate: 0.000 | time: 63.1 seconds\n",
      "Epoch: 024/14999 | Loss: 0.0089 | Episodes: 28 | Win count: 12 | Win rate: 0.500 | time: 64.2 seconds\n",
      "Epoch: 025/14999 | Loss: 0.0044 | Episodes: 11 | Win count: 13 | Win rate: 0.542 | time: 64.6 seconds\n",
      "Epoch: 026/14999 | Loss: 0.0059 | Episodes: 14 | Win count: 14 | Win rate: 0.583 | time: 65.2 seconds\n",
      "Epoch: 027/14999 | Loss: 0.0067 | Episodes: 8 | Win count: 15 | Win rate: 0.625 | time: 65.6 seconds\n",
      "Epoch: 028/14999 | Loss: 0.0067 | Episodes: 31 | Win count: 16 | Win rate: 0.667 | time: 67.2 seconds\n",
      "Epoch: 029/14999 | Loss: 0.0027 | Episodes: 108 | Win count: 17 | Win rate: 0.667 | time: 72.2 seconds\n",
      "Epoch: 030/14999 | Loss: 0.0217 | Episodes: 8 | Win count: 18 | Win rate: 0.708 | time: 72.5 seconds\n",
      "Epoch: 031/14999 | Loss: 0.0020 | Episodes: 39 | Win count: 19 | Win rate: 0.708 | time: 74.1 seconds\n",
      "Epoch: 032/14999 | Loss: 0.0030 | Episodes: 17 | Win count: 20 | Win rate: 0.708 | time: 74.8 seconds\n",
      "Epoch: 033/14999 | Loss: 0.0015 | Episodes: 1 | Win count: 21 | Win rate: 0.708 | time: 74.8 seconds\n",
      "Epoch: 034/14999 | Loss: 0.0023 | Episodes: 94 | Win count: 22 | Win rate: 0.750 | time: 78.8 seconds\n",
      "Epoch: 035/14999 | Loss: 0.0029 | Episodes: 11 | Win count: 23 | Win rate: 0.792 | time: 79.2 seconds\n",
      "Epoch: 036/14999 | Loss: 0.0018 | Episodes: 21 | Win count: 24 | Win rate: 0.833 | time: 80.1 seconds\n",
      "Epoch: 037/14999 | Loss: 0.0015 | Episodes: 47 | Win count: 25 | Win rate: 0.833 | time: 82.3 seconds\n",
      "Epoch: 038/14999 | Loss: 0.0023 | Episodes: 26 | Win count: 26 | Win rate: 0.833 | time: 83.4 seconds\n",
      "Epoch: 039/14999 | Loss: 0.0014 | Episodes: 12 | Win count: 27 | Win rate: 0.875 | time: 83.9 seconds\n",
      "Epoch: 040/14999 | Loss: 0.0013 | Episodes: 8 | Win count: 28 | Win rate: 0.917 | time: 84.3 seconds\n",
      "Epoch: 041/14999 | Loss: 0.0253 | Episodes: 38 | Win count: 29 | Win rate: 0.958 | time: 85.8 seconds\n",
      "Epoch: 042/14999 | Loss: 0.0015 | Episodes: 20 | Win count: 30 | Win rate: 0.958 | time: 86.6 seconds\n",
      "Epoch: 043/14999 | Loss: 0.0020 | Episodes: 19 | Win count: 31 | Win rate: 0.958 | time: 87.4 seconds\n",
      "Epoch: 044/14999 | Loss: 0.0009 | Episodes: 2 | Win count: 32 | Win rate: 1.000 | time: 87.5 seconds\n",
      "Epoch: 045/14999 | Loss: 0.0011 | Episodes: 27 | Win count: 33 | Win rate: 1.000 | time: 88.6 seconds\n",
      "Reached 100% win rate at epoch: 45\n",
      "files: model.h5, model.json\n",
      "n_epoch: 45, max_mem: 392, data: 32, time: 88.8 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ms.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After thoughts\n",
    "After 45 epoch's, it seems that our ML model has figured out our game. As you can see, it started at (1, 1) and it's path is denoted by the orange tiles. Again, the starting position is always randomly determined. It then navigated through the barriers (black), avoided the enemy (red), and successfully made it to the treasure (yellow). Neat!\n",
    "\n",
    "\n",
    "Although we only had a 7x7 map with 1 enemy, it is easy to see that this can be replicated at a much larger scale. With the same rules, and same goal, our reinforcement ML model will be able to solve any map with enough training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
